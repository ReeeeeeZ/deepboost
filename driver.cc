/*
Copyright 2015 Google Inc. All rights reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
*/

#include <chrono>
#include <sys/resource.h>
#include <unistd.h>
#include <algorithm>
#include <random>

#include "gflags/gflags.h"
#include "glog/logging.h"
#include "boost.h"
#include "io.h"
#include "types.h"

// å£°æ˜FLAGSå˜é‡ï¼ˆä¸æ˜¯å®šä¹‰ï¼‰
DECLARE_string(data_filename);
DECLARE_string(data_set);
DEFINE_int32(num_iter, 30, "Number of boosting iterations");
DECLARE_int32(tree_depth);
DECLARE_int32(num_folds);
DECLARE_int32(fold_to_cv);
DECLARE_int32(fold_to_test);
DECLARE_double(beta);
DECLARE_double(lambda);
DECLARE_string(loss_type);
DEFINE_int32(seed, 42, "Random seed");
DECLARE_double(noise_prob);

// æ–°å¢çš„FLAGSå®šä¹‰
DEFINE_string(test_filename, "", "Test data filename (optional, for standard train/test split)");

// å…¨å±€éšæœºæ•°ç”Ÿæˆå™¨
std::mt19937 rng;

void ValidateFlags() {
  CHECK_GE(FLAGS_num_iter, 1);
  CHECK_GE(FLAGS_tree_depth, 1);
  CHECK_GE(FLAGS_num_folds, 1);
  CHECK_GE(FLAGS_fold_to_cv, 0);
  CHECK_LT(FLAGS_fold_to_cv, FLAGS_num_folds);
  CHECK_GE(FLAGS_fold_to_test, 0);
  CHECK_LT(FLAGS_fold_to_test, FLAGS_num_folds);
  CHECK_NE(FLAGS_fold_to_cv, FLAGS_fold_to_test);
  CHECK_GT(FLAGS_beta, 0);
  CHECK_GT(FLAGS_lambda, 0);
  CHECK(FLAGS_loss_type == "exponential" || FLAGS_loss_type == "logistic");
  CHECK_GE(FLAGS_noise_prob, 0.0);
  CHECK_LE(FLAGS_noise_prob, 1.0);
}

void SetSeed(int seed) {
  rng.seed(seed);
}

int main(int argc, char** argv) {
  // è®°å½•å¼€å§‹æ—¶é—´
  auto start_time = std::chrono::high_resolution_clock::now();
  
  gflags::ParseCommandLineFlags(&argc, &argv, true);
  google::InitGoogleLogging(argv[0]);

  ValidateFlags();
  SetSeed(FLAGS_seed);

  vector<Example> train_examples, cv_examples, test_examples;
  
  // è®°å½•æ•°æ®è¯»å–å¼€å§‹æ—¶é—´
  auto data_start = std::chrono::high_resolution_clock::now();
  
  // åˆ¤æ–­ä½¿ç”¨å“ªç§æ•°æ®è¯»å–æ–¹å¼
  if (!FLAGS_test_filename.empty()) {
    printf("Using standard train/test split...\n");
    // ä½¿ç”¨æ ‡å‡†è®­ç»ƒ/æµ‹è¯•åˆ†å‰²
    ReadDataStandardSplit(&train_examples, &test_examples, 
                         FLAGS_data_filename, FLAGS_test_filename);
    
    // ä»è®­ç»ƒé›†ä¸­åˆ†å‡ºéªŒè¯é›†ï¼ˆå¯é€‰ï¼‰
    if (FLAGS_num_folds > 1) {
      std::shuffle(train_examples.begin(), train_examples.end(), rng);
      int cv_size = train_examples.size() / FLAGS_num_folds;
      cv_examples.assign(train_examples.begin(), train_examples.begin() + cv_size);
      train_examples.erase(train_examples.begin(), train_examples.begin() + cv_size);
      
      printf("Created CV set of size %zu from training data\n", cv_examples.size());
      
      // é‡æ–°è®¾ç½®æƒé‡
      const float initial_wgt = 1.0 / train_examples.size();
      for (Example& example : train_examples) {
        example.weight = initial_wgt;
      }
    }
  } else {
    printf("Using random split from single file...\n");
    // ä½¿ç”¨åŸæ¥çš„éšæœºåˆ†å‰²æ–¹å¼
    ReadData(&train_examples, &cv_examples, &test_examples);
  }
  
  auto data_end = std::chrono::high_resolution_clock::now();
  auto data_duration = std::chrono::duration_cast<std::chrono::milliseconds>(data_end - data_start);
  
  // è¾“å‡ºæ•°æ®é›†ä¿¡æ¯ï¼ˆä¿ç•™åŸæœ‰æ ¼å¼ï¼‰
  printf("=== Dataset Information ===\n");
  printf("Training examples: %zu\n", train_examples.size());
  printf("CV examples: %zu\n", cv_examples.size());
  printf("Test examples: %zu\n", test_examples.size());
  printf("Total examples: %zu\n", train_examples.size() + cv_examples.size() + test_examples.size());
  printf("Features per example: %zu\n", train_examples.empty() ? 0 : train_examples[0].values.size());
  printf("Data loading time: %ld ms\n", data_duration.count());
  
  // æ˜¾ç¤ºæ ‡ç­¾åˆ†å¸ƒ
  if (!train_examples.empty()) {
    int pos_train = 0, neg_train = 0;
    for (const Example& ex : train_examples) {
      if (ex.label == 1) pos_train++;
      else neg_train++;
    }
    
    int pos_test = 0, neg_test = 0;
    for (const Example& ex : test_examples) {
      if (ex.label == 1) pos_test++;
      else neg_test++;
    }
    
    printf("Train label distribution - Positive: %d (%.1f%%), Negative: %d (%.1f%%)\n",
           pos_train, 100.0 * pos_train / train_examples.size(),
           neg_train, 100.0 * neg_train / train_examples.size());
    printf("Test label distribution - Positive: %d (%.1f%%), Negative: %d (%.1f%%)\n",
           pos_test, 100.0 * pos_test / test_examples.size(),
           neg_test, 100.0 * neg_test / test_examples.size());
  }
  
  printf("===========================\n\n");

  Model model;
  
  // è®°å½•è®­ç»ƒå¼€å§‹æ—¶é—´
  auto train_start = std::chrono::high_resolution_clock::now();
  
  for (int iter = 1; iter <= FLAGS_num_iter; ++iter) {
    auto iter_start = std::chrono::high_resolution_clock::now();
    
    AddTreeToModel(train_examples, &model);
    
    auto iter_end = std::chrono::high_resolution_clock::now();
    auto iter_duration = std::chrono::duration_cast<std::chrono::milliseconds>(iter_end - iter_start);
    
    float cv_error, test_error, avg_tree_size;
    int num_trees;
    
    // å¦‚æœæœ‰CVé›†ï¼Œè¯„ä¼°CVé”™è¯¯ï¼Œå¦åˆ™æ˜¾ç¤ºN/A
    if (!cv_examples.empty()) {
      EvaluateModel(cv_examples, model, &cv_error, &avg_tree_size, &num_trees);
    } else {
      cv_error = -1; // æ ‡è®°æ— CVæ•°æ®
    }
    
    EvaluateModel(test_examples, model, &test_error, &avg_tree_size, &num_trees);
    
    // è·å–å†…å­˜ä½¿ç”¨æƒ…å†µ
    struct rusage usage;
    long memory_kb = 0;
    if (getrusage(RUSAGE_SELF, &usage) == 0) {
      memory_kb = usage.ru_maxrss;
#ifdef __APPLE__
      memory_kb /= 1024; // macOSä¸Šru_maxrssæ˜¯å­—èŠ‚ï¼Œè½¬æ¢ä¸ºKB
#endif
    }
    
    auto total_elapsed = std::chrono::duration_cast<std::chrono::milliseconds>(iter_end - train_start);
    
    // æ ¹æ®æ˜¯å¦æœ‰CVæ•°æ®è°ƒæ•´è¾“å‡ºæ ¼å¼
    if (cv_error >= 0) {
      printf("Iteration: %d, test error: %g, cv error: %g, "
             "avg tree size: %g, num trees: %d, "
             "iter time: %ld ms, total time: %ld ms, memory: %ld KB\n",
             iter, test_error, cv_error, avg_tree_size, num_trees,
             iter_duration.count(), total_elapsed.count(), memory_kb);
    } else {
      printf("Iteration: %d, test error: %g, cv error: N/A, "
             "avg tree size: %g, num trees: %d, "
             "iter time: %ld ms, total time: %ld ms, memory: %ld KB\n",
             iter, test_error, avg_tree_size, num_trees,
             iter_duration.count(), total_elapsed.count(), memory_kb);
    }
  }
  
  // è¾“å‡ºæ€»ä½“ç»Ÿè®¡ï¼ˆä¿ç•™åŸæœ‰æ ¼å¼ï¼‰
  auto end_time = std::chrono::high_resolution_clock::now();
  auto total_duration = std::chrono::duration_cast<std::chrono::milliseconds>(end_time - start_time);
  
  printf("\n=== Training Summary ===\n");
  printf("Total training time: %ld ms (%.2f seconds)\n", 
         total_duration.count(), total_duration.count() / 1000.0);
  printf("Final model trees: %zu\n", model.size());
  
  // è®¡ç®—æœ€ç»ˆå‡†ç¡®ç‡
  float final_test_error, final_avg_tree_size;
  int final_num_trees;
  EvaluateModel(test_examples, model, &final_test_error, &final_avg_tree_size, &final_num_trees);
  printf("Final test accuracy: %.2f%%\n", (1.0 - final_test_error) * 100.0);
  
  // ä¸åŸºå‡†å¯¹æ¯”
  printf("\n=== Benchmark Comparison ===\n");
  printf("DeepBoost:       %.2f%% accuracy (%.2f%% error)\n", 
         (1.0 - final_test_error) * 100.0, final_test_error * 100.0);
  printf("NBTree:          85.90%% accuracy (14.10%% error) [benchmark]\n");
  printf("FSS Naive Bayes: 85.95%% accuracy (14.05%% error) [benchmark]\n");
  printf("C4.5-auto:       85.54%% accuracy (14.46%% error) [benchmark]\n");
  
  if (final_test_error < 0.1405) {
    printf("ğŸ‰ DeepBoost OUTPERFORMS the best benchmark!\n");
  } else if (final_test_error < 0.1410) {
    printf("âœ… DeepBoost matches top-tier performance!\n");
  } else if (final_test_error < 0.1446) {
    printf("ğŸ‘ DeepBoost performs well compared to benchmarks.\n");
  }
  
  printf("========================\n");
  
  return 0;
}